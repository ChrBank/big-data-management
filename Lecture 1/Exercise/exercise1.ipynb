{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a60f826",
   "metadata": {},
   "source": [
    "# Dataframe exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0aded5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame from a dictionary:\n",
      "    X   Y   Z\n",
      "0  78  84  86\n",
      "1  85  94  97\n",
      "2  96  89  96\n",
      "3  80  83  72\n",
      "4  86  86  83\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Exericse 1\n",
    "\n",
    "# Creating a DataFrame from a Dictionary\n",
    "# Write a Pandas program to create a dataframe from a dictionary and display it.\n",
    "# Sample data: {'X':[78,85,96,80,86], 'Y':[84,94,89,83,86],'Z':[86,97,96,72,83]}\n",
    "\n",
    "df1 = pd.DataFrame(\n",
    "   {'X':[78,85,96,80,86], \n",
    "   'Y':[84,94,89,83,86],\n",
    "   'Z':[86,97,96,72,83]}\n",
    "   )\n",
    "\n",
    "print(\"DataFrame from a dictionary:\")\n",
    "print(df1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b342cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame from a dictionary with index labels:\n",
      "        name  score  attempts qualify\n",
      "a  Anastasia   12.5         1     yes\n",
      "b       Dima    9.0         3      no\n",
      "c  Katherine   16.5         2     yes\n",
      "d      James    NaN         3      no\n",
      "e      Emily    9.0         2      no\n",
      "f    Michael   20.0         3     yes\n",
      "g    Matthew   14.5         1     yes\n",
      "h      Laura    NaN         1      no\n",
      "i      Kevin    8.0         2      no\n",
      "j      Jonas   19.0         1     yes\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Exercise 2\n",
    "\n",
    "# DataFrame with Specified Index Labels\n",
    "\n",
    "# Write a Pandas program to create and display a DataFrame from a specified dictionary data which has the index labels.\n",
    "\n",
    "# Sample Python dictionary data and list labels:\n",
    "exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "   'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "   'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "   'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df2 = pd.DataFrame(exam_data, index=labels)\n",
    "\n",
    "print(\"\\nDataFrame from a dictionary with index labels:\")\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5faeebed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the basic information about this DataFrame and its data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10 entries, a to j\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   name      10 non-null     object \n",
      " 1   score     8 non-null      float64\n",
      " 2   attempts  10 non-null     int64  \n",
      " 3   qualify   10 non-null     object \n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 400.0+ bytes\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3\n",
    "# DataFrame Basic Summary Information\n",
    "\n",
    "# Write a Pandas program to display a summary of the basic information about a specified DataFrame and its data.\n",
    "\n",
    "# Sample Python dictionary data and list labels:\n",
    "exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df3 = pd.DataFrame(exam_data, index=labels)\n",
    "\n",
    "print(\"Summary of the basic information about this DataFrame and its data:\")\n",
    "print(df3.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2199e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print the first 3 rows of a given DataFrame\n",
      "        name  score  attempts qualify\n",
      "a  Anastasia   12.5         1     yes\n",
      "b       Dima    9.0         3      no\n",
      "c  Katherine   16.5         2     yes\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4\n",
    "# Selecting the First 3 Rows\n",
    "\n",
    "# Write a Pandas program to get the first 3 rows of a given DataFrame.\n",
    "\n",
    "# Sample Python dictionary data and list labels:\n",
    "exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df4 = pd.DataFrame(exam_data, index=labels)\n",
    "\n",
    "print(\"Print the first 3 rows of a given DataFrame\")\n",
    "\n",
    "print(df4.head(3))\n",
    "\n",
    "# could also use slicing\n",
    "\n",
    "#print(df4.iloc[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf33959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select the 'name' and 'score' columns from the DataFrame:\n",
      "        name  score\n",
      "a  Anastasia   12.5\n",
      "b       Dima    9.0\n",
      "c  Katherine   16.5\n",
      "d      James    NaN\n",
      "e      Emily    9.0\n",
      "f    Michael   20.0\n",
      "g    Matthew   14.5\n",
      "h      Laura    NaN\n",
      "i      Kevin    8.0\n",
      "j      Jonas   19.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5\n",
    "# Selecting 'name' and 'score' Columns\n",
    "\n",
    "# Write a Pandas program to select the 'name' and 'score' columns from the following DataFrame.\n",
    "\n",
    "# Sample Python dictionary data and list labels:\n",
    "exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df5 = pd.DataFrame(exam_data, index=labels)\n",
    "\n",
    "print(\"Select the 'name' and 'score' columns from the DataFrame:\")\n",
    "print(df5[['name','score']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef538f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select specific columns and rows:\n",
      "      name  score\n",
      "b     Dima    9.0\n",
      "d    James    NaN\n",
      "f  Michael   20.0\n",
      "g  Matthew   14.5\n"
     ]
    }
   ],
   "source": [
    "# Exercise 6\n",
    "# Selecting Specific Columns and Rows\n",
    "\n",
    "# Write a Pandas program to select the specified columns and rows from a given data frame.\n",
    "\n",
    "# Sample Python dictionary data and list labels:\n",
    "# Select 'name' and 'score' columns in rows 1, 3, 5, 6 from the following data frame.\n",
    "exam_data = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df6 = pd.DataFrame(exam_data, index = labels)\n",
    "\n",
    "print(\"Select specific columns and rows:\")\n",
    "print(df6.iloc[[1,3,5,6], [0,1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b7baf4",
   "metadata": {},
   "source": [
    "# Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b2ba90fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrames:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "-------------------------------------\n",
      "  student_id              name  marks\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "\n",
      "Join the said two dataframes along rows:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "0         S4  Scarlette Fisher    201\n",
      "1         S5  Carla Williamson    200\n",
      "2         S6       Dante Morse    198\n",
      "3         S7    Kaiser William    219\n",
      "4         S8   Madeeha Preston    201\n",
      "\n",
      "Join the said two dataframes along columns:\n",
      "  student_id              name  marks student_id              name  marks\n",
      "0         S1  Danniella Fenton    200         S4  Scarlette Fisher    201\n",
      "1         S2      Ryder Storey    210         S5  Carla Williamson    200\n",
      "2         S3      Bryce Jensen    190         S6       Dante Morse    198\n",
      "3         S4         Ed Bernal    222         S7    Kaiser William    219\n",
      "4         S5       Kwame Morin    199         S8   Madeeha Preston    201\n",
      "\n",
      "Append rows to an existing DF\n",
      "  student_id              name  marks\n",
      "0         S6  Scarlette Fisher    205\n",
      "\n",
      "Combined Data:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "5         S6  Scarlette Fisher    205\n",
      "\n",
      "Append a list of dictioneries or series to a existing DataFrame\n",
      "\n",
      "New students\n",
      "  student_id              name  marks\n",
      "0         S6  Scarlette Fisher    203\n",
      "1         S7      Bryce Jensen    207\n",
      "\n",
      "Combined Data:\n",
      "  student_id              name  marks\n",
      "0         S1  Danniella Fenton    200\n",
      "1         S2      Ryder Storey    210\n",
      "2         S3      Bryce Jensen    190\n",
      "3         S4         Ed Bernal    222\n",
      "4         S5       Kwame Morin    199\n",
      "5         S6  Scarlette Fisher    203\n",
      "6         S7      Bryce Jensen    207\n",
      "\n",
      "Now join the said result_data and df_exam_data along student_id:\n",
      "  student_id              name  marks  exam_id\n",
      "0         S1  Danniella Fenton    200       23\n",
      "1         S2      Ryder Storey    210       45\n",
      "2         S3      Bryce Jensen    190       12\n",
      "3         S4         Ed Bernal    222       67\n",
      "4         S5       Kwame Morin    199       21\n",
      "5         S4  Scarlette Fisher    201       67\n",
      "6         S5  Carla Williamson    200       21\n",
      "7         S7    Kaiser William    219       55\n",
      "8         S8   Madeeha Preston    201       33\n",
      "\n",
      "Join the two dataframes using the common column of both dataframes\n",
      "  student_id       name_x  marks_x            name_y  marks_y\n",
      "0         S4    Ed Bernal      222  Scarlette Fisher      201\n",
      "1         S5  Kwame Morin      199  Carla Williamson      200\n",
      "\n",
      "Join the two dataframes with matching records from both sides where available\n",
      "Merged data (outer join):\n",
      "  student_id            name_x  marks_x            name_y  marks_y\n",
      "0         S1  Danniella Fenton    200.0               NaN      NaN\n",
      "1         S2      Ryder Storey    210.0               NaN      NaN\n",
      "2         S3      Bryce Jensen    190.0               NaN      NaN\n",
      "3         S4         Ed Bernal    222.0  Scarlette Fisher    201.0\n",
      "4         S5       Kwame Morin    199.0  Carla Williamson    200.0\n",
      "5         S6               NaN      NaN       Dante Morse    198.0\n",
      "6         S7               NaN      NaN    Kaiser William    219.0\n",
      "7         S8               NaN      NaN   Madeeha Preston    201.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "\n",
    "# Join DataFrames along Rows (Join Rows)\n",
    "# Write a Pandas program to join the two given dataframes along rows and assign all data.\n",
    "\n",
    "student_data1 = pd.DataFrame({\n",
    "   'student_id':['S1', 'S2', 'S3', 'S4', 'S5'],\n",
    "   'name':['Danniella Fenton', 'Ryder Storey', 'Bryce Jensen', 'Ed Bernal', 'Kwame Morin'],\n",
    "   'marks': [200, 210, 190, 222, 199]})\n",
    "\n",
    "student_data2 = pd.DataFrame( {\n",
    "   'student_id':['S4', 'S5', 'S6', 'S7', 'S8'],\n",
    "   'name':['Scarlette Fisher', 'Carla Williamson', 'Dante Morse', 'Kaiser William', 'Madeeha Preston'],\n",
    "   'marks': [201, 200, 198, 219, 201]})\n",
    "\n",
    "print(\"Original DataFrames:\")\n",
    "print(student_data1)\n",
    "print(\"-------------------------------------\")\n",
    "print(student_data2)\n",
    "print(\"\\nJoin the said two dataframes along rows:\")\n",
    "result_data = pd.concat([student_data1, student_data2])\n",
    "print(result_data)\n",
    "\n",
    "# Exercise 2\n",
    "# Join DataFrames along Columns (Join Columns)\n",
    "\n",
    "# Write a Pandas program to join the two given dataframes along columns and assign all data.\n",
    "\n",
    "print(\"\\nJoin the said two dataframes along columns:\")\n",
    "result_data2 = pd.concat([student_data1, student_data2], axis=1)\n",
    "print(result_data2)\n",
    "\n",
    "\n",
    "# Exercise 3\n",
    "# Append Rows to Existing DataFrame\n",
    "\n",
    "# Write a Pandas program to append rows to an existing DataFrame and display the combined data.\n",
    "\n",
    "print(\"\\nAppend rows to an existing DF\")\n",
    "new_student = pd.DataFrame({\n",
    "   'student_id':['S6'],\n",
    "   'name': ['Scarlette Fisher'],\n",
    "   'marks': [205]})\n",
    "\n",
    "print(new_student)\n",
    "combined_data = pd.concat([student_data1, new_student], ignore_index = True)\n",
    "print(\"\\nCombined Data:\")\n",
    "print(combined_data)\n",
    "\n",
    "# Exercise 4\n",
    "# Append List of Dictionaries/Series\n",
    "\n",
    "# Write a Pandas program to append a list of dictioneries or series to a existing DataFrame and display the combined data.\n",
    "\n",
    "print(\"\\nAppend a list of dictioneries or series to a existing DataFrame\")\n",
    "dicts = [{'student_id': 'S6', 'name': 'Scarlette Fisher', 'marks': 203},\n",
    "         {'student_id': 'S7', 'name': 'Bryce Jensen', 'marks': 207}]\n",
    "\n",
    "new_students = pd.DataFrame(dicts)\n",
    "print(\"\\nNew students\")\n",
    "print(new_students)\n",
    "\n",
    "combined_data2 = pd.concat([student_data1, new_students], ignore_index=True)\n",
    "print(\"\\nCombined Data:\")\n",
    "print(combined_data2)\n",
    "\n",
    "# Exercise 5\n",
    "# Join Rows and Merge with Another DataFrame\n",
    "\n",
    "# Write a Pandas program to join the two given dataframes along rows and merge with another dataframe along the common column id.\n",
    "\n",
    "exam_data2 = pd.DataFrame({\n",
    "        'student_id': ['S1', 'S2', 'S3', 'S4', 'S5', 'S7', 'S8', 'S9', 'S10', 'S11', 'S12', 'S13'],\n",
    "        'exam_id': [23, 45, 12, 67, 21, 55, 33, 14, 56, 83, 88, 12]})\n",
    "\n",
    "print(\"\\nNow join the said result_data and df_exam_data along student_id:\")\n",
    "final_merged_data = pd.merge(result_data, exam_data2, on='student_id')\n",
    "print(final_merged_data)\n",
    "\n",
    "# Exercise 6\n",
    "# Join DataFrames Using Common Column â€“\n",
    "\n",
    "# Write a Pandas program to join the two dataframes using the common column of both dataframes.\n",
    "\n",
    "print(\"\\nJoin the two dataframes using the common column of both dataframes\")\n",
    "merge_data_2 = pd.merge(student_data1, student_data2, on='student_id', how='inner')\n",
    "print(merge_data_2)\n",
    "\n",
    "# Exercise 7\n",
    "# Join with Matching Records (Inner Join)\n",
    "\n",
    "# Write a Pandas program to join the two dataframes with matching records from both sides where available.\n",
    "print(\"\\nJoin the two dataframes with matching records from both sides where available\")\n",
    "merged_data3 = pd.merge(student_data1, student_data2, on='student_id', how='outer')\n",
    "print(\"Merged data (outer join):\")\n",
    "print(merged_data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1454e1",
   "metadata": {},
   "source": [
    "# Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "055f3a11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World alcohol consumption sample data:\n",
      "   Year       WHO region                Country Beverage Types  Display Value\n",
      "0  1986  Western Pacific               Viet Nam           Wine           0.00\n",
      "1  1986         Americas                Uruguay          Other           0.50\n",
      "2  1985           Africa           Cte d'Ivoire           Wine           1.62\n",
      "3  1986         Americas               Colombia           Beer           4.27\n",
      "4  1987         Americas  Saint Kitts and Nevis           Beer           1.98\n",
      "\n",
      "Shape of the dataframe:  (100, 5)\n",
      "\n",
      "Number of rows:  100\n",
      "\n",
      "Number of column:  5\n",
      "\n",
      "Extract Column Names:\n",
      "Index(['Year', 'WHO region', 'Country', 'Beverage Types', 'Display Value'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "\n",
    "# Dataset Dimensions\n",
    "\n",
    "# Write a Pandas program to display the dimensions or shape of the World alcohol consumption dataset. Also extract the column names from the dataset.\n",
    "\n",
    "w_a_con = pd.read_csv('world_alcohol.csv')\n",
    "print(\"World alcohol consumption sample data:\")\n",
    "print(w_a_con.head())\n",
    "print('\\nShape of the dataframe: ',w_a_con.shape)\n",
    "print('\\nNumber of rows: ',w_a_con.shape[0])\n",
    "print('\\nNumber of column: ',w_a_con.shape[1])\n",
    "print(\"\\nExtract Column Names:\")\n",
    "print(w_a_con.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c0e5d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World alcohol consumption sample data:\n",
      "   Year       WHO region                Country Beverage Types  Display Value\n",
      "0  1986  Western Pacific               Viet Nam           Wine           0.00\n",
      "1  1986         Americas                Uruguay          Other           0.50\n",
      "2  1985           Africa           Cte d'Ivoire           Wine           1.62\n",
      "3  1986         Americas               Colombia           Beer           4.27\n",
      "4  1987         Americas  Saint Kitts and Nevis           Beer           1.98\n",
      "\n",
      "Select first 2 rows:\n",
      "   Year       WHO region   Country Beverage Types  Display Value\n",
      "0  1986  Western Pacific  Viet Nam           Wine            0.0\n",
      "1  1986         Americas   Uruguay          Other            0.5\n",
      "\n",
      "Select first 2 columns:\n",
      "   Year       WHO region\n",
      "0  1986  Western Pacific\n",
      "1  1986         Americas\n",
      "2  1985           Africa\n",
      "3  1986         Americas\n",
      "4  1987         Americas\n",
      "\n",
      "Select 2 specific columns:\n",
      "    Display Value  Year\n",
      "0            0.00  1986\n",
      "1            0.50  1986\n",
      "2            1.62  1985\n",
      "3            4.27  1986\n",
      "4            1.98  1987\n",
      "..            ...   ...\n",
      "95           0.00  1984\n",
      "96           7.38  1985\n",
      "97           0.00  1984\n",
      "98           0.00  1984\n",
      "99           0.00  1985\n",
      "\n",
      "[100 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2\n",
    "# Row and Column Slicing\n",
    "\n",
    "# Write a Pandas program to select first 2 rows, 2 columns and specific two columns from World alcohol consumption dataset.\n",
    "\n",
    "print(\"World alcohol consumption sample data:\")\n",
    "print(w_a_con.head())\n",
    "print(\"\\nSelect first 2 rows:\")\n",
    "print(w_a_con.iloc[:2])\n",
    "print(\"\\nSelect first 2 columns:\")\n",
    "print(w_a_con.iloc[:,:2].head())\n",
    "print(\"\\nSelect 2 specific columns:\")\n",
    "print(w_a_con[['Display Value', 'Year']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a311ac54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World alcohol consumption sample data:\n",
      "   Year       WHO region                Country Beverage Types  Display Value\n",
      "0  1986  Western Pacific               Viet Nam           Wine           0.00\n",
      "1  1986         Americas                Uruguay          Other           0.50\n",
      "2  1985           Africa           Cte d'Ivoire           Wine           1.62\n",
      "3  1986         Americas               Colombia           Beer           4.27\n",
      "4  1987         Americas  Saint Kitts and Nevis           Beer           1.98\n",
      "\n",
      "Select random number of rows:\n",
      "    Year       WHO region       Country Beverage Types  Display Value\n",
      "11  1989         Americas     Guatemala           Beer           0.62\n",
      "24  1985           Africa       Comoros          Other            NaN\n",
      "5   1987         Americas     Guatemala          Other           0.00\n",
      "39  1987           Africa  Burkina Faso        Spirits           0.01\n",
      "97  1984  South-East Asia     Indonesia           Wine           0.00\n",
      "\n",
      "Select a fraction of random rows:\n",
      "    Year             WHO region                     Country Beverage Types  \\\n",
      "92  1986                 Africa                     Eritrea        Spirits   \n",
      "83  1986                 Europe                     Ukraine          Other   \n",
      "60  1987  Eastern Mediterranean  Iran (Islamic Republic of)          Other   \n",
      "20  1986        South-East Asia                     Myanmar           Wine   \n",
      "52  1986  Eastern Mediterranean                Saudi Arabia           Wine   \n",
      "\n",
      "    Display Value  \n",
      "92            0.0  \n",
      "83            NaN  \n",
      "60            0.0  \n",
      "20            0.0  \n",
      "52            0.0  \n"
     ]
    }
   ],
   "source": [
    "# Exercise 3\n",
    "# Random Sampling of Rows\n",
    "\n",
    "# Write a Pandas program to select random number of rows, fraction of random rows from World alcohol consumption dataset.\n",
    "\n",
    "print(\"World alcohol consumption sample data:\")\n",
    "print(w_a_con.head())\n",
    "print(\"\\nSelect random number of rows:\")\n",
    "print(w_a_con.sample(5))\n",
    "print(\"\\nSelect a fraction of random rows:\")\n",
    "print(w_a_con.sample(frac=0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "abe48223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World alcohol consumption sample data:\n",
      "   Year       WHO region                Country Beverage Types  Display Value\n",
      "0  1986  Western Pacific               Viet Nam           Wine           0.00\n",
      "1  1986         Americas                Uruguay          Other           0.50\n",
      "2  1985           Africa           Cte d'Ivoire           Wine           1.62\n",
      "3  1986         Americas               Colombia           Beer           4.27\n",
      "4  1987         Americas  Saint Kitts and Nevis           Beer           1.98\n",
      "\n",
      "Missing values:\n",
      "     Year  WHO region  Country  Beverage Types  Display Value\n",
      "0   False       False    False           False          False\n",
      "1   False       False    False           False          False\n",
      "2   False       False    False           False          False\n",
      "3   False       False    False           False          False\n",
      "4   False       False    False           False          False\n",
      "..    ...         ...      ...             ...            ...\n",
      "95  False       False    False           False          False\n",
      "96  False       False    False           False          False\n",
      "97  False       False    False           False          False\n",
      "98  False       False    False           False          False\n",
      "99  False       False    False           False          False\n",
      "\n",
      "[100 rows x 5 columns]\n",
      "\n",
      "Dropping the missing values:\n",
      "    Year       WHO region                                Country  \\\n",
      "0   1986  Western Pacific                               Viet Nam   \n",
      "1   1986         Americas                                Uruguay   \n",
      "2   1985           Africa                           Cte d'Ivoire   \n",
      "3   1986         Americas                               Colombia   \n",
      "4   1987         Americas                  Saint Kitts and Nevis   \n",
      "..   ...              ...                                    ...   \n",
      "95  1984           Africa                                  Niger   \n",
      "96  1985           Europe                             Luxembourg   \n",
      "97  1984  South-East Asia                              Indonesia   \n",
      "98  1984           Africa                      Equatorial Guinea   \n",
      "99  1985  South-East Asia  Democratic People's Republic of Korea   \n",
      "\n",
      "   Beverage Types  Display Value  \n",
      "0            Wine           0.00  \n",
      "1           Other           0.50  \n",
      "2            Wine           1.62  \n",
      "3            Beer           4.27  \n",
      "4            Beer           1.98  \n",
      "..            ...            ...  \n",
      "95          Other           0.00  \n",
      "96           Wine           7.38  \n",
      "97           Wine           0.00  \n",
      "98           Wine           0.00  \n",
      "99           Wine           0.00  \n",
      "\n",
      "[95 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4\n",
    "# Missing Value Handling\n",
    "\n",
    "# Write a Pandas program to find and drop the missing values from World alcohol consumption dataset.\n",
    "\n",
    "print(\"World alcohol consumption sample data:\")\n",
    "print(w_a_con.head())\n",
    "print(\"\\nMissing values:\")\n",
    "print(w_a_con.isnull())\n",
    "print(\"\\nDropping the missing values:\")\n",
    "print(w_a_con.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d76e8859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "World alcohol consumption sample data:\n",
      "   Year       WHO region                Country Beverage Types  Display Value\n",
      "0  1986  Western Pacific               Viet Nam           Wine           0.00\n",
      "1  1986         Americas                Uruguay          Other           0.50\n",
      "2  1985           Africa           Cte d'Ivoire           Wine           1.62\n",
      "3  1986         Americas               Colombia           Beer           4.27\n",
      "4  1987         Americas  Saint Kitts and Nevis           Beer           1.98\n",
      "\n",
      "After removing the duplicates of WHO region column:\n",
      "    Year             WHO region       Country Beverage Types  Display Value\n",
      "0   1986        Western Pacific      Viet Nam           Wine           0.00\n",
      "1   1986               Americas       Uruguay          Other           0.50\n",
      "2   1985                 Africa  Cte d'Ivoire           Wine           1.62\n",
      "13  1984  Eastern Mediterranean   Afghanistan          Other           0.00\n",
      "18  1984                 Europe        Norway        Spirits           1.62\n",
      "20  1986        South-East Asia       Myanmar           Wine           0.00\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5\n",
    "# Duplicate Removal in 'WHO region'\n",
    "\n",
    "# Write a Pandas program to remove the duplicates from 'WHO region' column of World alcohol consumption dataset.\n",
    "\n",
    "print(\"World alcohol consumption sample data:\")\n",
    "print(w_a_con.head())\n",
    "\n",
    "print(\"\\nAfter removing the duplicates of WHO region column:\")\n",
    "print(w_a_con.drop_duplicates('WHO region'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cf7e32ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The world alcohol consumption details in the year 1985:\n",
      "    Year       WHO region                                            Country  \\\n",
      "2   1985           Africa                                       Cte d'Ivoire   \n",
      "7   1985           Africa                                             Angola   \n",
      "12  1985  Western Pacific                   Lao People's Democratic Republic   \n",
      "14  1985  Western Pacific                                           Viet Nam   \n",
      "24  1985           Africa                                            Comoros   \n",
      "26  1985           Europe  United Kingdom of Great Britain and Northern I...   \n",
      "33  1985           Africa                                         Mauritania   \n",
      "35  1985         Americas                              Saint Kitts and Nevis   \n",
      "44  1985           Europe                                          Lithuania   \n",
      "50  1985           Europe                                        Switzerland   \n",
      "\n",
      "   Beverage Types  Display Value  \n",
      "2            Wine           1.62  \n",
      "7         Spirits           0.39  \n",
      "12           Beer           0.00  \n",
      "14        Spirits           0.05  \n",
      "24          Other            NaN  \n",
      "26           Wine           1.36  \n",
      "33          Other           0.00  \n",
      "35        Spirits           2.24  \n",
      "44          Other            NaN  \n",
      "50          Other           0.30  \n",
      "\n",
      "The world alcohol consumption details in the year 1989:\n",
      "    Year             WHO region                           Country  \\\n",
      "11  1989               Americas                         Guatemala   \n",
      "17  1989                 Africa                        Seychelles   \n",
      "21  1989               Americas                        Costa Rica   \n",
      "32  1989                 Africa                         Mauritius   \n",
      "45  1989                 Africa                          Zimbabwe   \n",
      "55  1989               Americas                          Suriname   \n",
      "57  1989                 Europe                           Croatia   \n",
      "59  1989  Eastern Mediterranean              Syrian Arab Republic   \n",
      "64  1989               Americas  Bolivia (Plurinational State of)   \n",
      "65  1989  Eastern Mediterranean                           Somalia   \n",
      "\n",
      "   Beverage Types  Display Value  \n",
      "11           Beer           0.62  \n",
      "17           Beer           2.23  \n",
      "21        Spirits           4.51  \n",
      "32           Beer           1.60  \n",
      "45           Beer           0.19  \n",
      "55           Wine           0.04  \n",
      "57           Wine           5.10  \n",
      "59          Other           0.00  \n",
      "64           Beer           1.26  \n",
      "65           Beer           0.00  \n"
     ]
    }
   ],
   "source": [
    "# Exercise 6\n",
    "# Filtering by Year\n",
    "\n",
    "# Write a Pandas program to find out the alcohol consumption of a given year from the world alcohol consumption dataset.\n",
    "\n",
    "print(\"\\nThe world alcohol consumption details in the year 1985:\")\n",
    "print(w_a_con[w_a_con['Year']==1985].head(10))\n",
    "print(\"\\nThe world alcohol consumption details in the year 1989:\")\n",
    "print(w_a_con[w_a_con['Year']==1989].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c7c53a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The world alcohol consumption details where year is 1987 or 1989:\n",
      "    Year       WHO region                Country Beverage Types  Display Value\n",
      "4   1987         Americas  Saint Kitts and Nevis           Beer           1.98\n",
      "5   1987         Americas              Guatemala          Other           0.00\n",
      "6   1987           Africa              Mauritius           Wine           0.13\n",
      "10  1987           Africa               Botswana           Wine           0.20\n",
      "11  1989         Americas              Guatemala           Beer           0.62\n",
      "15  1987           Africa          Guinea-Bissau           Wine           0.07\n",
      "17  1989           Africa             Seychelles           Beer           2.23\n",
      "21  1989         Americas             Costa Rica        Spirits           4.51\n",
      "28  1987  Western Pacific               Viet Nam           Beer           0.11\n",
      "32  1989           Africa              Mauritius           Beer           1.60\n"
     ]
    }
   ],
   "source": [
    "# Exercise 7\n",
    "# Filtering by Multiple Years\n",
    "\n",
    "# Write a Pandas program to find out the alcohol consumption details in the year '1987' or '1989' from the world alcohol consumption dataset.\n",
    "\n",
    "print(\"\\nThe world alcohol consumption details where year is 1987 or 1989:\")\n",
    "print((w_a_con[(w_a_con['Year']==1987) | (w_a_con['Year']==1989)]).head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83233b13",
   "metadata": {},
   "source": [
    "# Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "22a6814c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "     ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
      "0   70001.0     150.50  2012-10-05         3002       5002.0\n",
      "1       NaN     270.65  2012-09-10         3001       5003.0\n",
      "2   70002.0      65.26         NaN         3001       5001.0\n",
      "3   70004.0     110.50  2012-08-17         3003          NaN\n",
      "4       NaN     948.50  2012-09-10         3002       5002.0\n",
      "5   70005.0    2400.60  2012-07-27         3001       5001.0\n",
      "6       NaN    5760.00  2012-09-10         3001       5001.0\n",
      "7   70010.0    1983.43  2012-10-10         3004          NaN\n",
      "8   70003.0    2480.40  2012-10-10         3003       5003.0\n",
      "9   70012.0     250.45  2012-06-27         3002       5002.0\n",
      "10      NaN      75.29  2012-08-17         3001       5003.0\n",
      "11  70013.0    3045.60  2012-04-25         3001          NaN\n",
      "\n",
      "Missing values of the said dataframe:\n",
      "    ord_no  purch_amt  ord_date  customer_id  salesman_id\n",
      "0    False      False     False        False        False\n",
      "1     True      False     False        False        False\n",
      "2    False      False      True        False        False\n",
      "3    False      False     False        False         True\n",
      "4     True      False     False        False        False\n",
      "5    False      False     False        False        False\n",
      "6     True      False     False        False        False\n",
      "7    False      False     False        False         True\n",
      "8    False      False     False        False        False\n",
      "9    False      False     False        False        False\n",
      "10    True      False     False        False        False\n",
      "11   False      False     False        False         True\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "# Detect Missing Values\n",
    "\n",
    "# Write a Pandas program to detect missing values of a given DataFrame. Display True or False.\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,np.nan,70010,70003,70012,np.nan,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,3003,3002,3001,3001],\n",
    "'salesman_id':[5002,5003,5001,np.nan,5002,5001,5001,np.nan,5003,5002,5003,np.nan]})\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nMissing values of the said dataframe:\")\n",
    "print(df.isna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "439f4b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "     ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
      "0   70001.0     150.50  2012-10-05         3002       5002.0\n",
      "1       NaN     270.65  2012-09-10         3001       5003.0\n",
      "2   70002.0      65.26         NaN         3001       5001.0\n",
      "3   70004.0     110.50  2012-08-17         3003          NaN\n",
      "4       NaN     948.50  2012-09-10         3002       5002.0\n",
      "5   70005.0    2400.60  2012-07-27         3001       5001.0\n",
      "6       NaN    5760.00  2012-09-10         3001       5001.0\n",
      "7   70010.0    1983.43  2012-10-10         3004          NaN\n",
      "8   70003.0    2480.40  2012-10-10         3003       5003.0\n",
      "9   70012.0     250.45  2012-06-27         3002       5002.0\n",
      "10      NaN      75.29  2012-08-17         3001       5003.0\n",
      "11  70013.0    3045.60  2012-04-25         3001          NaN\n",
      "\n",
      "Identify the columns which have at least one missing value:\n",
      "ord_no          True\n",
      "purch_amt      False\n",
      "ord_date        True\n",
      "customer_id    False\n",
      "salesman_id     True\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2\n",
    "# Identify Columns with Missing Values\n",
    "\n",
    "# Write a Pandas program to identify the column(s) of a given DataFrame which have at least one missing value.\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,np.nan,70010,70003,70012,np.nan,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,3003,3002,3001,3001],\n",
    "'salesman_id':[5002,5003,5001,np.nan,5002,5001,5001,np.nan,5003,5002,5003,np.nan]})\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nIdentify the columns which have at least one missing value:\")\n",
    "print(df.isna().any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c04cbf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "     ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
      "0   70001.0     150.50  2012-10-05         3002       5002.0\n",
      "1       NaN     270.65  2012-09-10         3001       5003.0\n",
      "2   70002.0      65.26         NaN         3001       5001.0\n",
      "3   70004.0     110.50  2012-08-17         3003          NaN\n",
      "4       NaN     948.50  2012-09-10         3002       5002.0\n",
      "5   70005.0    2400.60  2012-07-27         3001       5001.0\n",
      "6       NaN    5760.00  2012-09-10         3001       5001.0\n",
      "7   70010.0    1983.43  2012-10-10         3004          NaN\n",
      "8   70003.0    2480.40  2012-10-10         3003       5003.0\n",
      "9   70012.0     250.45  2012-06-27         3002       5002.0\n",
      "10      NaN      75.29  2012-08-17         3001       5003.0\n",
      "11  70013.0    3045.60  2012-04-25         3001          NaN\n",
      "\n",
      "Number of missing values of the said dataframe:\n",
      "ord_no         4\n",
      "purch_amt      0\n",
      "ord_date       1\n",
      "customer_id    0\n",
      "salesman_id    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3\n",
    "# Count Missing Values in Each Column\n",
    "# Write a Pandas program to count the number of missing values in each column of a given DataFrame.\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,np.nan,70010,70003,70012,np.nan,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,3003,3002,3001,3001],\n",
    "'salesman_id':[5002,5003,5001,np.nan,5002,5001,5001,np.nan,5003,5002,5003,np.nan]})\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nNumber of missing values of the said dataframe:\")\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2959fa4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "   ord_no purch_amt    ord_date customer_id salesman_id\n",
      "0   70001     150.5           ?        3002        5002\n",
      "1     NaN    270.65  2012-09-10        3001        5003\n",
      "2   70002     65.26         NaN        3001           ?\n",
      "3   70004     110.5  2012-08-17        3003        5001\n",
      "4     NaN     948.5  2012-09-10        3002         NaN\n",
      "5   70005    2400.6  2012-07-27        3001        5002\n",
      "6      --      5760  2012-09-10        3001        5001\n",
      "7   70010         ?  2012-10-10        3004           ?\n",
      "8   70003     12.43  2012-10-10          --        5003\n",
      "9   70012    2480.4  2012-06-27        3002        5002\n",
      "10    NaN    250.45  2012-08-17        3001        5003\n",
      "11  70013    3045.6  2012-04-25        3001          --\n",
      "\n",
      "Replace the missing values with NaN:\n",
      "     ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
      "0   70001.0     150.50         NaN       3002.0       5002.0\n",
      "1       NaN     270.65  2012-09-10       3001.0       5003.0\n",
      "2   70002.0      65.26         NaN       3001.0          NaN\n",
      "3   70004.0     110.50  2012-08-17       3003.0       5001.0\n",
      "4       NaN     948.50  2012-09-10       3002.0          NaN\n",
      "5   70005.0    2400.60  2012-07-27       3001.0       5002.0\n",
      "6       NaN    5760.00  2012-09-10       3001.0       5001.0\n",
      "7   70010.0        NaN  2012-10-10       3004.0          NaN\n",
      "8   70003.0      12.43  2012-10-10          NaN       5003.0\n",
      "9   70012.0    2480.40  2012-06-27       3002.0       5002.0\n",
      "10      NaN     250.45  2012-08-17       3001.0       5003.0\n",
      "11  70013.0    3045.60  2012-04-25       3001.0          NaN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qz/g8cr90mj3rn1zcl7111g7lkm0000gn/T/ipykernel_24442/3365379086.py:17: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  result = df.replace({\"?\": np.nan, \"--\": np.nan})\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4\n",
    "# Replace Non-Valuable Missing Values\n",
    "\n",
    "# Write a Pandas program to find and replace the missing values in a given DataFrame which do not have any valuable information.\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,\"--\",70010,70003,70012,np.nan,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,\"?\",12.43,2480.4,250.45, 3045.6],\n",
    "'ord_date': ['?','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,\"--\",3002,3001,3001],\n",
    "'salesman_id':[5002,5003,\"?\",5001,np.nan,5002,5001,\"?\",5003,5002,5003,\"--\"]})\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nReplace the missing values with NaN:\")\n",
    "result = df.replace({\"?\": np.nan, \"--\": np.nan})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "97d1517a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Orders DataFrame:\n",
      "     ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
      "0   70001.0     150.50  2012-10-05         3002       5002.0\n",
      "1       NaN     270.65  2012-09-10         3001       5003.0\n",
      "2   70002.0      65.26         NaN         3001       5001.0\n",
      "3   70004.0     110.50  2012-08-17         3003          NaN\n",
      "4       NaN     948.50  2012-09-10         3002       5002.0\n",
      "5   70005.0    2400.60  2012-07-27         3001       5001.0\n",
      "6       NaN    5760.00  2012-09-10         3001       5001.0\n",
      "7   70010.0    1983.43  2012-10-10         3004          NaN\n",
      "8   70003.0    2480.40  2012-10-10         3003       5003.0\n",
      "9   70012.0     250.45  2012-06-27         3002       5002.0\n",
      "10      NaN      75.29  2012-08-17         3001       5003.0\n",
      "11  70013.0    3045.60  2012-04-25         3001          NaN\n",
      "\n",
      "Drop the rows where at least one element is missing:\n",
      "    ord_no  purch_amt    ord_date  customer_id  salesman_id\n",
      "0  70001.0     150.50  2012-10-05         3002       5002.0\n",
      "5  70005.0    2400.60  2012-07-27         3001       5001.0\n",
      "8  70003.0    2480.40  2012-10-10         3003       5003.0\n",
      "9  70012.0     250.45  2012-06-27         3002       5002.0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5\n",
    "# Drop Rows with Any Missing Value\n",
    "\n",
    "# Write a Pandas program to drop the rows where at least one element is missing in a given DataFrame.\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "df = pd.DataFrame({\n",
    "'ord_no':[70001,np.nan,70002,70004,np.nan,70005,np.nan,70010,70003,70012,np.nan,70013],\n",
    "'purch_amt':[150.5,270.65,65.26,110.5,948.5,2400.6,5760,1983.43,2480.4,250.45, 75.29,3045.6],\n",
    "'ord_date': ['2012-10-05','2012-09-10',np.nan,'2012-08-17','2012-09-10','2012-07-27','2012-09-10','2012-10-10','2012-10-10','2012-06-27','2012-08-17','2012-04-25'],\n",
    "'customer_id':[3002,3001,3001,3003,3002,3001,3001,3004,3003,3002,3001,3001],\n",
    "'salesman_id':[5002,5003,5001,np.nan,5002,5001,5001,np.nan,5003,5002,5003,np.nan]})\n",
    "\n",
    "print(\"Original Orders DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nDrop the rows where at least one element is missing:\")\n",
    "result = df.dropna()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d725e9",
   "metadata": {},
   "source": [
    "# Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f150d5f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Split the said data on school_code wise:\n",
      "\n",
      "Group:\n",
      "('s001',)\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S4  street1  \n",
      "\n",
      "Group:\n",
      "('s002',)\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  \n",
      "\n",
      "Group:\n",
      "('s003',)\n",
      "   school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3\n",
      "\n",
      "Group:\n",
      "('s004',)\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n",
      "\n",
      "Type of the object:\n",
      "<class 'pandas.core.groupby.generic.DataFrameGroupBy'>\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "# Grouping by School Code\n",
    "\n",
    "# Write a Pandas program to split the following dataframe into groups based on school code. Also check the type of GroupBy object.\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nSplit the said data on school_code wise:')\n",
    "result = student_data.groupby(['school_code'])\n",
    "for name,group in result:\n",
    "    print(\"\\nGroup:\")\n",
    "    print(name)\n",
    "    print(group)\n",
    "print(\"\\nType of the object:\")\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "529de622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Mean, min, and max value of age for each value of the school:\n",
      "              age        \n",
      "             mean min max\n",
      "school_code              \n",
      "s001         12.5  12  13\n",
      "s002         13.0  12  14\n",
      "s003         13.0  13  13\n",
      "s004         12.0  12  12\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2\n",
    "# Grouping by School Code with Age Aggregation\n",
    "\n",
    "# Write a Pandas program to split the following dataframe by school code and get mean, min, and max value of age for each school.\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nMean, min, and max value of age for each value of the school:')\n",
    "grouped_single = student_data.groupby('school_code').agg({'age': ['mean', 'min', 'max']})\n",
    "print(grouped_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "e9956978",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Split the said data on school_code, class wise:\n",
      "\n",
      "Group:\n",
      "('s001', 'V')\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "\n",
      "Group:\n",
      "('s001', 'VI')\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S4        s001    VI  Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S4  street1  \n",
      "\n",
      "Group:\n",
      "('s002', 'V')\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  \n",
      "\n",
      "Group:\n",
      "('s003', 'VI')\n",
      "   school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3\n",
      "\n",
      "Group:\n",
      "('s004', 'VI')\n",
      "   school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  \n"
     ]
    }
   ],
   "source": [
    "# Exercise 3\n",
    "# Grouping by School Code and Class\n",
    "\n",
    "# Write a Pandas program to split the following given dataframe into groups based on school code and class.\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nSplit the said data on school_code, class wise:')\n",
    "result = student_data.groupby(['school_code', 'class'])\n",
    "for name,group in result:\n",
    "    print(\"\\nGroup:\")\n",
    "    print(name)\n",
    "    print(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7348fdb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Cast grouping as a list:\n",
      "[(('s001',),    school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S4  street1  ), (('s002',),    school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S2        s002     V  Gino Mcneill     17/05/2002   12     192      32   \n",
      "S5        s002     V  Gino Mcneill     11/05/2002   14     151      31   \n",
      "\n",
      "    address  \n",
      "S2  street2  \n",
      "S5  street2  ), (('s003',),    school_code class         name date_Of_Birth   age  height  weight  address\n",
      "S3        s003    VI  Ryan Parkes     16/02/1999   13     186      33  street3), (('s004',),    school_code class          name date_Of_Birth   age  height  weight  \\\n",
      "S6        s004    VI  David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S6  street4  )]\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4\n",
    "# Grouping by School Code with List Conversion\n",
    "\n",
    "# Write a Pandas program to split the following given dataframe into groups based on school code and cast grouping as a list.\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nCast grouping as a list:')\n",
    "result = student_data.groupby(['school_code'])\n",
    "print(list(result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c9bc8cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "   school_code class            name date_Of_Birth   age  height  weight  \\\n",
      "S1        s001     V  Alberto Franco     15/05/2002   12     173      35   \n",
      "S2        s002     V    Gino Mcneill     17/05/2002   12     192      32   \n",
      "S3        s003    VI     Ryan Parkes     16/02/1999   13     186      33   \n",
      "S4        s001    VI    Eesha Hinton     25/09/1998   13     167      30   \n",
      "S5        s002     V    Gino Mcneill     11/05/2002   14     151      31   \n",
      "S6        s004    VI    David Parkes     15/09/1997   12     159      32   \n",
      "\n",
      "    address  \n",
      "S1  street1  \n",
      "S2  street2  \n",
      "S3  street3  \n",
      "S4  street1  \n",
      "S5  street2  \n",
      "S6  street4  \n",
      "\n",
      "Split the said data on school_code wise:\n",
      "Size of the grouped data - single column\n",
      "school_code\n",
      "s001    2\n",
      "s002    2\n",
      "s003    1\n",
      "s004    1\n",
      "dtype: int64\n",
      "\n",
      "Split the said data on school_code and class wise:\n",
      "Size of the grouped data - multiple columns:\n",
      "school_code  class\n",
      "s001         V        1\n",
      "             VI       1\n",
      "s002         V        2\n",
      "s003         VI       1\n",
      "s004         VI       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5\n",
    "# Grouping by Single and Multiple Columns â€“ Group Size\n",
    "\n",
    "# Write a Pandas program to split the following given dataframe into groups based on single column and multiple columns. \n",
    "# Find the size of the grouped data.\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "#pd.set_option('display.max_columns', None)\n",
    "student_data = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'age': [12, 12, 13, 13, 14, 12],\n",
    "    'height': [173, 192, 186, 167, 151, 159],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=['S1', 'S2', 'S3', 'S4', 'S5', 'S6'])\n",
    "\n",
    "print(\"Original DataFrame:\")\n",
    "print(student_data)\n",
    "print('\\nSplit the said data on school_code wise:')\n",
    "grouped_single = student_data.groupby(['school_code'])\n",
    "print(\"Size of the grouped data - single column\")\n",
    "print(grouped_single.size())\n",
    "print('\\nSplit the said data on school_code and class wise:')\n",
    "\n",
    "grouped_mul = student_data.groupby(['school_code', 'class'])\n",
    "print(\"Size of the grouped data - multiple columns:\")\n",
    "print(grouped_mul.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d444307",
   "metadata": {},
   "source": [
    "# Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "323752ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Index:\n",
      "  school_code class            name date_Of_Birth  weight  address t_id\n",
      "0        s001     V  Alberto Franco    15/05/2002      35  street1   t1\n",
      "1        s002     V    Gino Mcneill    17/05/2002      32  street2   t2\n",
      "2        s003    VI     Ryan Parkes    16/02/1999      33  street3   t3\n",
      "3        s001    VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
      "4        s002     V    Gino Mcneill    11/05/2002      31  street2   t5\n",
      "5        s004    VI    David Parkes    15/09/1997      32  street4   t6\n",
      "\n",
      "school_code as new Index:\n",
      "            class            name date_Of_Birth  weight  address t_id\n",
      "school_code                                                          \n",
      "s001            V  Alberto Franco    15/05/2002      35  street1   t1\n",
      "s002            V    Gino Mcneill    17/05/2002      32  street2   t2\n",
      "s003           VI     Ryan Parkes    16/02/1999      33  street3   t3\n",
      "s001           VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
      "s002            V    Gino Mcneill    11/05/2002      31  street2   t5\n",
      "s004           VI    David Parkes    15/09/1997      32  street4   t6\n",
      "\n",
      "t_id as new Index:\n",
      "     school_code class            name date_Of_Birth  weight  address\n",
      "t_id                                                                 \n",
      "t1          s001     V  Alberto Franco    15/05/2002      35  street1\n",
      "t2          s002     V    Gino Mcneill    17/05/2002      32  street2\n",
      "t3          s003    VI     Ryan Parkes    16/02/1999      33  street3\n",
      "t4          s001    VI    Eesha Hinton    25/09/1998      30  street1\n",
      "t5          s002     V    Gino Mcneill    11/05/2002      31  street2\n",
      "t6          s004    VI    David Parkes    15/09/1997      32  street4\n"
     ]
    }
   ],
   "source": [
    "# Exercise 1\n",
    "# Display Default and Set Column as Index\n",
    "\n",
    "# Write a Pandas program to display the default index and set a column as an Index in a given dataframe.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4'],\n",
    "    't_id':['t1', 't2', 't3', 't4', 't5', 't6']})\n",
    "print(\"Default Index:\")\n",
    "print(df.head(10))\n",
    "print(\"\\nschool_code as new Index:\")\n",
    "df1 = df.set_index('school_code')\n",
    "print(df1)\n",
    "print(\"\\nt_id as new Index:\")\n",
    "df2 = df.set_index('t_id')\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f6a44104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original DataFrame:\n",
      "  school_code class            name date_Of_Birth  weight  address t_id\n",
      "0        s001     V  Alberto Franco    15/05/2002      35  street1   t1\n",
      "1        s002     V    Gino Mcneill    17/05/2002      32  street2   t2\n",
      "2        s003    VI     Ryan Parkes    16/02/1999      33  street3   t3\n",
      "3        s001    VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
      "4        s002     V    Gino Mcneill    11/05/2002      31  street2   t5\n",
      "5        s004    VI    David Parkes    15/09/1997      32  street4   t6\n",
      "\n",
      "MultiIndex using columns 't_id' and â€˜school_codeâ€™:\n",
      "                 class            name date_Of_Birth  weight  address\n",
      "t_id school_code                                                     \n",
      "t1   s001            V  Alberto Franco    15/05/2002      35  street1\n",
      "t2   s002            V    Gino Mcneill    17/05/2002      32  street2\n",
      "t3   s003           VI     Ryan Parkes    16/02/1999      33  street3\n",
      "t4   s001           VI    Eesha Hinton    25/09/1998      30  street1\n",
      "t5   s002            V    Gino Mcneill    11/05/2002      31  street2\n",
      "t6   s004           VI    David Parkes    15/09/1997      32  street4\n",
      "\n",
      "MultiIndex using an Index and a column:\n",
      "       school_code class            name date_Of_Birth  weight  address\n",
      "  t_id                                                                 \n",
      "0 t1          s001     V  Alberto Franco    15/05/2002      35  street1\n",
      "1 t2          s002     V    Gino Mcneill    17/05/2002      32  street2\n",
      "2 t3          s003    VI     Ryan Parkes    16/02/1999      33  street3\n",
      "3 t4          s001    VI    Eesha Hinton    25/09/1998      30  street1\n",
      "4 t5          s002     V    Gino Mcneill    11/05/2002      31  street2\n",
      "5 t6          s004    VI    David Parkes    15/09/1997      32  street4\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2\n",
    "# Create MultiIndex Frame\n",
    "\n",
    "# Write a Pandas program to create a multi Index frame using two columns and using an Index and a column.\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4'],\n",
    "    't_id':['t1', 't2', 't3', 't4', 't5', 't6']})\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nMultiIndex using columns 't_id' and â€˜school_codeâ€™:\")\n",
    "df1 = df.set_index(['t_id', 'school_code'])\n",
    "print(df1)\n",
    "print(\"\\nMultiIndex using an Index and a column:\")\n",
    "df2 = df.set_index([pd.Index([0, 1, 2, 3, 4, 5]), 't_id'])\n",
    "print(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "442ce063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Index:\n",
      "  school_code class            name date_Of_Birth  weight  address t_id\n",
      "0        s001     V  Alberto Franco    15/05/2002      35  street1   t1\n",
      "1        s002     V    Gino Mcneill    17/05/2002      32  street2   t2\n",
      "2        s003    VI     Ryan Parkes    16/02/1999      33  street3   t3\n",
      "3        s001    VI    Eesha Hinton    25/09/1998      30  street1   t4\n",
      "4        s002     V    Gino Mcneill    11/05/2002      31  street2   t5\n",
      "5        s004    VI    David Parkes    15/09/1997      32  street4   t6\n",
      "\n",
      "t_id as new Index:\n",
      "     school_code class            name date_Of_Birth  weight  address\n",
      "t_id                                                                 \n",
      "t1          s001     V  Alberto Franco    15/05/2002      35  street1\n",
      "t2          s002     V    Gino Mcneill    17/05/2002      32  street2\n",
      "t3          s003    VI     Ryan Parkes    16/02/1999      33  street3\n",
      "t4          s001    VI    Eesha Hinton    25/09/1998      30  street1\n",
      "t5          s002     V    Gino Mcneill    11/05/2002      31  street2\n",
      "t6          s004    VI    David Parkes    15/09/1997      32  street4\n",
      "\n",
      "Reset the index:\n",
      "  t_id school_code class            name date_Of_Birth  weight  address\n",
      "0   t1        s001     V  Alberto Franco    15/05/2002      35  street1\n",
      "1   t2        s002     V    Gino Mcneill    17/05/2002      32  street2\n",
      "2   t3        s003    VI     Ryan Parkes    16/02/1999      33  street3\n",
      "3   t4        s001    VI    Eesha Hinton    25/09/1998      30  street1\n",
      "4   t5        s002     V    Gino Mcneill    11/05/2002      31  street2\n",
      "5   t6        s004    VI    David Parkes    15/09/1997      32  street4\n"
     ]
    }
   ],
   "source": [
    "# Exericse 3\n",
    "# Reset Index After Setting Column as Index\n",
    "\n",
    "# Write a Pandas program to display the default index and set a column as an Index in a given dataframe and then reset the index.\n",
    "df = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4'],\n",
    "    't_id':['t1', 't2', 't3', 't4', 't5', 't6']})\n",
    "print(\"Default Index:\")\n",
    "print(df.head(10))\n",
    "print(\"\\nt_id as new Index:\")\n",
    "df1 = df.set_index('t_id')\n",
    "print(df1)\n",
    "print(\"\\nReset the index:\")\n",
    "df2 = df1.reset_index(inplace=False)\n",
    "print(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5b239275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an Int64Index:\n",
      "  school_code class            name date_Of_Birth  weight  address\n",
      "1        s001     V  Alberto Franco    15/05/2002      35  street1\n",
      "2        s002     V    Gino Mcneill    17/05/2002      32  street2\n",
      "3        s003    VI     Ryan Parkes    16/02/1999      33  street3\n",
      "4        s001    VI    Eesha Hinton    25/09/1998      30  street1\n",
      "5        s002     V    Gino Mcneill    11/05/2002      31  street2\n",
      "6        s004    VI    David Parkes    15/09/1997      32  street4\n",
      "\n",
      "View the Index:\n",
      "Index([1, 2, 3, 4, 5, 6], dtype='int64')\n",
      "\n",
      "Floating-point labels using Float64Index:\n",
      "    school_code class            name date_Of_Birth   weight  address\n",
      "0.1        s001     V  Alberto Franco     15/05/2002      35  street1\n",
      "0.2        s002     V    Gino Mcneill     17/05/2002      32  street2\n",
      "0.3        s003    VI     Ryan Parkes     16/02/1999      33  street3\n",
      "0.4        s001    VI    Eesha Hinton     25/09/1998      30  street1\n",
      "0.5        s002     V    Gino Mcneill     11/05/2002      31  street2\n",
      "0.6        s004    VI    David Parkes     15/09/1997      32  street4\n",
      "\n",
      "View the Index:\n",
      "Index([0.1, 0.2, 0.3, 0.4, 0.5, 0.6], dtype='float64')\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4\n",
    "# Create 64-bit Integer and Float Index Labels\n",
    "\n",
    "# Write a Pandas program to create an index labels by using 64-bit integers, using floating-point numbers in a given dataframe.\n",
    "\n",
    "print(\"Create an Int64Index:\")\n",
    "df_i64 = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=[1, 2, 3, 4, 5, 6])\n",
    "print(df_i64)\n",
    "print(\"\\nView the Index:\")\n",
    "print(df_i64.index)\n",
    "\n",
    "print(\"\\nFloating-point labels using Float64Index:\")\n",
    "df_f64 = pd.DataFrame({\n",
    "    'school_code': ['s001','s002','s003','s001','s002','s004'],\n",
    "    'class': ['V', 'V', 'VI', 'VI', 'V', 'VI'],\n",
    "    'name': ['Alberto Franco','Gino Mcneill','Ryan Parkes', 'Eesha Hinton', 'Gino Mcneill', 'David Parkes'],\n",
    "    'date_Of_Birth ': ['15/05/2002','17/05/2002','16/02/1999','25/09/1998','11/05/2002','15/09/1997'],\n",
    "    'weight': [35, 32, 33, 30, 31, 32],\n",
    "    'address': ['street1', 'street2', 'street3', 'street1', 'street2', 'street4']},\n",
    "    index=[.1, .2, .3, .4, .5, .6])\n",
    "print(df_f64)\n",
    "print(\"\\nView the Index:\")\n",
    "print(df_f64.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2dc08f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an Interval Index using IntervalIndex.from_breaks:\n",
      "            X\n",
      "(0.0, 0.5]  1\n",
      "(0.5, 1.0]  2\n",
      "(1.0, 1.5]  3\n",
      "(1.5, 2.0]  4\n",
      "(2.0, 2.5]  5\n",
      "(2.5, 3.0]  6\n",
      "(3.0, 3.5]  7\n",
      "IntervalIndex([(0.0, 0.5], (0.5, 1.0], (1.0, 1.5], (1.5, 2.0], (2.0, 2.5],\n",
      "               (2.5, 3.0], (3.0, 3.5]],\n",
      "              dtype='interval[float64, right]')\n",
      "\n",
      "Create an Interval Index using IntervalIndex.from_tuples:\n",
      "            X\n",
      "(0.0, 0.5]  1\n",
      "(0.5, 1.0]  2\n",
      "(1.0, 1.5]  3\n",
      "(1.5, 2.0]  4\n",
      "(2.0, 2.5]  5\n",
      "(2.5, 3.0]  6\n",
      "(3.0, 3.5]  7\n",
      "IntervalIndex([(0.0, 0.5], (0.5, 1.0], (1.0, 1.5], (1.5, 2.0], (2.0, 2.5],\n",
      "               (2.5, 3.0], (3.0, 3.5]],\n",
      "              dtype='interval[float64, right]')\n",
      "\n",
      "Create an Interval Index using IntervalIndex.from_arrays:\n",
      "            X\n",
      "(0.0, 0.5]  1\n",
      "(0.5, 1.0]  2\n",
      "(1.0, 1.5]  3\n",
      "(1.5, 2.0]  4\n",
      "(2.0, 2.5]  5\n",
      "(2.5, 3.0]  6\n",
      "(3.0, 3.5]  7\n",
      "IntervalIndex([(0.0, 0.5], (0.5, 1.0], (1.0, 1.5], (1.5, 2.0], (2.0, 2.5],\n",
      "               (2.5, 3.0], (3.0, 3.5]],\n",
      "              dtype='interval[float64, right]')\n"
     ]
    }
   ],
   "source": [
    "# Exercise 5\n",
    "# DataFrame with Interval Index\n",
    "\n",
    "# Write a Pandas program to create a DataFrame using intervals as an index.\n",
    "\n",
    "print(\"Create an Interval Index using IntervalIndex.from_breaks:\")\n",
    "df_interval = pd.DataFrame({\"X\":[1, 2, 3, 4, 5, 6, 7]},\n",
    "                            index = pd.IntervalIndex.from_breaks(\n",
    "                            [0, 0.5, 1.0, 1.5, 2.0, 2.5, 3, 3.5]))    \n",
    "print(df_interval)\n",
    "print(df_interval.index)\n",
    "\n",
    "print(\"\\nCreate an Interval Index using IntervalIndex.from_tuples:\")\n",
    "df_interval = pd.DataFrame({\"X\":[1, 2, 3, 4, 5, 6, 7]},             \n",
    "                            index = pd.IntervalIndex.from_tuples(\n",
    "                            [(0, .5), (.5, 1), (1, 1.5), (1.5, 2), (2, 2.5), (2.5, 3), (3, 3.5)]))\n",
    "print(df_interval)\n",
    "print(df_interval.index)\n",
    "\n",
    "print(\"\\nCreate an Interval Index using IntervalIndex.from_arrays:\")\n",
    "df_interval = pd.DataFrame({\"X\":[1, 2, 3, 4, 5, 6, 7]},             \n",
    "                            index = pd.IntervalIndex.from_arrays(\n",
    "                            [0, .5, 1, 1.5, 2, 2.5, 3], [.5, 1, 1.5, 2, 2.5, 3, 3.5]))\n",
    "print(df_interval)\n",
    "print(df_interval.index) \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bdm25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
